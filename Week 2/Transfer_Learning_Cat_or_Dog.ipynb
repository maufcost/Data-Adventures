{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11509
    },
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "outputId": "87585a4d-a9b3-4c80-82b7-9eaaf0337c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-02 18:48:27--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.128, 2607:f8b0:4001:c03::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M   113MB/s    in 0.7s    \n",
      "\n",
      "2019-05-02 18:48:28 (113 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_94 (Batc (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_v1_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_95 (Batc (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_v1_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_96 (Batc (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_v1_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_97 (Batc (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_v1_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_98 (Batc (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_v1_98[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_102 (Bat (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_100 (Bat (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_103 (Bat (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_99 (Batc (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_101 (Bat (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_104 (Bat (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_105 (Bat (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_v1_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_109 (Bat (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_107 (Bat (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_110 (Bat (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_106 (Bat (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_108 (Bat (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_111 (Bat (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_112 (Bat (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_116 (Bat (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_114 (Bat (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_117 (Bat (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_113 (Bat (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_115 (Bat (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_118 (Bat (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_119 (Bat (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_121 (Bat (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_122 (Bat (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_120 (Bat (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_123 (Bat (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_v1_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_v1_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_128 (Bat (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_129 (Bat (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_125 (Bat (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_130 (Bat (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_126 (Bat (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_131 (Bat (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_124 (Bat (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_127 (Bat (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_132 (Bat (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_133 (Bat (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_138 (Bat (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_139 (Bat (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_135 (Bat (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_140 (Bat (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_136 (Bat (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_141 (Bat (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_134 (Bat (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_137 (Bat (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_142 (Bat (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_143 (Bat (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_148 (Bat (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_149 (Bat (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_149[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_145 (Bat (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_150 (Bat (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_150[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_146 (Bat (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_151 (Bat (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_151[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_144 (Bat (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_147 (Bat (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_152 (Bat (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_153 (Bat (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_152[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_153[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_158 (Bat (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_158[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_159 (Bat (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_155 (Bat (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_160 (Bat (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_155[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_160[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_156 (Bat (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_161 (Bat (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_156[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_161[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_154 (Bat (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_157 (Bat (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_162 (Bat (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_163 (Bat (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_154[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_157[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_162[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_163[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_166 (Bat (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_166[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_167 (Bat (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_167[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_164 (Bat (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_168 (Bat (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_164[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_168[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_165 (Bat (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_169 (Bat (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_165[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_169[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_174 (Bat (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_v1_174[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_171 (Bat (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_175 (Bat (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_171[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_175[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_172 (Bat (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_173 (Bat (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_176 (Bat (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_177 (Bat (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_170 (Bat (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_172[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_173[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_176[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_177[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_178 (Bat (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_170[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_178[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_183 (Bat (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_v1_183[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_180 (Bat (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_184 (Bat (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_180[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_184[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_181 (Bat (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_182 (Bat (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_185 (Bat (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_186 (Bat (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_179 (Bat (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_181[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_182[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_185[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_186[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_187 (Bat (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_179[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_187[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "('Last layer output shape: ', (None, 7, 7, 768))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Downloading trained weights from the inception model.\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = \"/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Instantiation model with pre-trained weights.\n",
    "# 'include_top' = whether or not to include the fully connected layer at the end\n",
    "# of the network (it's gonna be False because will be creating our own Dense \n",
    "# layer later and training it).\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Locking layers so that they are not retrained again when we use the 'fit' \n",
    "# function below.\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "# Printing the summary of the model.\n",
    "pre_trained_model.summary()\n",
    "  \n",
    "# Choosing a layer to be our last layer.\n",
    "last_layer = pre_trained_model.get_layer(\"mixed7\")\n",
    "print(\"Last layer output shape: \", last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [],
   "source": [
    "# Flattening the output layer to 1 dimension.\n",
    "x = layers.Flatten()(last_output)\n",
    "\n",
    "# Adding a fully connected layer with 1,024 hidden units and ReLU activation.\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "# Adding a dropout rate of 20%.\n",
    "x = layers.Dropout(0.2)(x)    \n",
    "\n",
    "# Adding a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation=\"sigmoid\")(x)           \n",
    "\n",
    "# Creating model.\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "# Compiling model.\n",
    "model.compile(optimizer = \"adam\", \n",
    "              loss = \"binary_crossentropy\", \n",
    "              metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "ac6d5fd0-db68-407f-e12d-7e7ca210fc98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-02 20:05:31--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 2607:f8b0:4001:c07::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
      "\n",
      "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   222MB/s    in 0.3s    \n",
      "\n",
      "2019-05-02 20:05:31 (222 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
      "\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Downloading cats and dogs dataset.\n",
    "!wget --no-check-certificate \\\n",
    "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "       -O /tmp/cats_and_dogs_filtered.zip\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Unzipping file.\n",
    "zip_file = zipfile.ZipFile(\"/tmp/cats_and_dogs_filtered.zip\", 'r')\n",
    "zip_file.extractall(\"/tmp\")\n",
    "zip_file.close()\n",
    "\n",
    "# Creating directories that I'll be using.\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs') # Directory with our validation dog pictures\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# Adding our data-augmentation parameters to ImageDataGenerator.\n",
    "training_data_generator = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_data_generator = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "\n",
    "# Flowing training images in batches of 20 using training_data_generator generator.\n",
    "training_data_generator = training_data_generator.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = \"binary\", \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using validation_data_generator generator\n",
    "validation_data_generator =  validation_data_generator.flow_from_directory(validation_dir,\n",
    "                                                          batch_size = 20,\n",
    "                                                          class_mode = \"binary\", \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5117
    },
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "f2689a99-3a37-4648-88b0-90f4a6ea4e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.5924 - acc: 0.9290\n",
      " - 22s - loss: 0.1284 - acc: 0.9465 - val_loss: 0.5924 - val_acc: 0.9290\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3684 - acc: 0.9600\n",
      " - 19s - loss: 0.1101 - acc: 0.9545 - val_loss: 0.3684 - val_acc: 0.9600\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4492 - acc: 0.9420\n",
      " - 19s - loss: 0.1392 - acc: 0.9460 - val_loss: 0.4492 - val_acc: 0.9420\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3588 - acc: 0.9500\n",
      " - 19s - loss: 0.1212 - acc: 0.9545 - val_loss: 0.3588 - val_acc: 0.9500\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4037 - acc: 0.9470\n",
      " - 20s - loss: 0.1175 - acc: 0.9525 - val_loss: 0.4037 - val_acc: 0.9470\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 5s 108ms/step - loss: 0.4623 - acc: 0.9400\n",
      " - 20s - loss: 0.1095 - acc: 0.9575 - val_loss: 0.4623 - val_acc: 0.9400\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4689 - acc: 0.9440\n",
      " - 19s - loss: 0.1163 - acc: 0.9535 - val_loss: 0.4689 - val_acc: 0.9440\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4593 - acc: 0.9430\n",
      " - 19s - loss: 0.1016 - acc: 0.9605 - val_loss: 0.4593 - val_acc: 0.9430\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4193 - acc: 0.9520\n",
      " - 20s - loss: 0.1099 - acc: 0.9550 - val_loss: 0.4193 - val_acc: 0.9520\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5796 - acc: 0.9390\n",
      " - 19s - loss: 0.1144 - acc: 0.9560 - val_loss: 0.5796 - val_acc: 0.9390\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.4801 - acc: 0.9400\n",
      " - 19s - loss: 0.1166 - acc: 0.9520 - val_loss: 0.4801 - val_acc: 0.9400\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.3852 - acc: 0.9540\n",
      " - 19s - loss: 0.1045 - acc: 0.9650 - val_loss: 0.3852 - val_acc: 0.9540\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.3825 - acc: 0.9520\n",
      " - 20s - loss: 0.1361 - acc: 0.9495 - val_loss: 0.3825 - val_acc: 0.9520\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 0.4152 - acc: 0.9520\n",
      " - 19s - loss: 0.1003 - acc: 0.9605 - val_loss: 0.4152 - val_acc: 0.9520\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4261 - acc: 0.9490\n",
      " - 19s - loss: 0.1072 - acc: 0.9615 - val_loss: 0.4261 - val_acc: 0.9490\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3445 - acc: 0.9580\n",
      " - 19s - loss: 0.1140 - acc: 0.9550 - val_loss: 0.3445 - val_acc: 0.9580\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 5s 106ms/step - loss: 0.3208 - acc: 0.9620\n",
      " - 19s - loss: 0.0950 - acc: 0.9630 - val_loss: 0.3208 - val_acc: 0.9620\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4211 - acc: 0.9480\n",
      " - 19s - loss: 0.1290 - acc: 0.9520 - val_loss: 0.4211 - val_acc: 0.9480\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.4156 - acc: 0.9500\n",
      " - 19s - loss: 0.0968 - acc: 0.9580 - val_loss: 0.4156 - val_acc: 0.9500\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3278 - acc: 0.9630\n",
      " - 19s - loss: 0.0965 - acc: 0.9605 - val_loss: 0.3278 - val_acc: 0.9630\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.4164 - acc: 0.9530\n",
      " - 19s - loss: 0.1155 - acc: 0.9560 - val_loss: 0.4164 - val_acc: 0.9530\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 5s 104ms/step - loss: 0.5047 - acc: 0.9440\n",
      " - 21s - loss: 0.1102 - acc: 0.9575 - val_loss: 0.5047 - val_acc: 0.9440\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.3683 - acc: 0.9530\n",
      " - 20s - loss: 0.1000 - acc: 0.9635 - val_loss: 0.3683 - val_acc: 0.9530\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4049 - acc: 0.9520\n",
      " - 19s - loss: 0.1091 - acc: 0.9545 - val_loss: 0.4049 - val_acc: 0.9520\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5423 - acc: 0.9430\n",
      " - 19s - loss: 0.1051 - acc: 0.9580 - val_loss: 0.5423 - val_acc: 0.9430\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4080 - acc: 0.9580\n",
      " - 20s - loss: 0.0879 - acc: 0.9705 - val_loss: 0.4080 - val_acc: 0.9580\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4513 - acc: 0.9530\n",
      " - 19s - loss: 0.0885 - acc: 0.9670 - val_loss: 0.4513 - val_acc: 0.9530\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.4563 - acc: 0.9490\n",
      " - 19s - loss: 0.1081 - acc: 0.9580 - val_loss: 0.4563 - val_acc: 0.9490\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4952 - acc: 0.9440\n",
      " - 19s - loss: 0.1081 - acc: 0.9565 - val_loss: 0.4952 - val_acc: 0.9440\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 5s 106ms/step - loss: 0.5208 - acc: 0.9440\n",
      " - 21s - loss: 0.1106 - acc: 0.9585 - val_loss: 0.5208 - val_acc: 0.9440\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.4567 - acc: 0.9480\n",
      " - 19s - loss: 0.1010 - acc: 0.9600 - val_loss: 0.4567 - val_acc: 0.9480\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4440 - acc: 0.9520\n",
      " - 19s - loss: 0.1058 - acc: 0.9600 - val_loss: 0.4440 - val_acc: 0.9520\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4836 - acc: 0.9510\n",
      " - 19s - loss: 0.1028 - acc: 0.9640 - val_loss: 0.4836 - val_acc: 0.9510\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 5s 105ms/step - loss: 0.4187 - acc: 0.9570\n",
      " - 20s - loss: 0.1231 - acc: 0.9560 - val_loss: 0.4187 - val_acc: 0.9570\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.4094 - acc: 0.9580\n",
      " - 19s - loss: 0.0833 - acc: 0.9660 - val_loss: 0.4094 - val_acc: 0.9580\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3553 - acc: 0.9610\n",
      " - 19s - loss: 0.1028 - acc: 0.9625 - val_loss: 0.3553 - val_acc: 0.9610\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3860 - acc: 0.9590\n",
      " - 19s - loss: 0.0992 - acc: 0.9610 - val_loss: 0.3860 - val_acc: 0.9590\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.4262 - acc: 0.9580\n",
      " - 20s - loss: 0.1028 - acc: 0.9595 - val_loss: 0.4262 - val_acc: 0.9580\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3280 - acc: 0.9590\n",
      " - 20s - loss: 0.1094 - acc: 0.9535 - val_loss: 0.3280 - val_acc: 0.9590\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3322 - acc: 0.9620\n",
      " - 19s - loss: 0.1033 - acc: 0.9620 - val_loss: 0.3322 - val_acc: 0.9620\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3686 - acc: 0.9590\n",
      " - 19s - loss: 0.1099 - acc: 0.9585 - val_loss: 0.3686 - val_acc: 0.9590\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 5s 100ms/step - loss: 0.4738 - acc: 0.9530\n",
      " - 19s - loss: 0.0992 - acc: 0.9610 - val_loss: 0.4738 - val_acc: 0.9530\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4475 - acc: 0.9510\n",
      " - 20s - loss: 0.1030 - acc: 0.9630 - val_loss: 0.4475 - val_acc: 0.9510\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4674 - acc: 0.9520\n",
      " - 19s - loss: 0.1044 - acc: 0.9635 - val_loss: 0.4674 - val_acc: 0.9520\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4799 - acc: 0.9500\n",
      " - 19s - loss: 0.0898 - acc: 0.9670 - val_loss: 0.4799 - val_acc: 0.9500\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 5s 104ms/step - loss: 0.4431 - acc: 0.9540\n",
      " - 19s - loss: 0.1210 - acc: 0.9550 - val_loss: 0.4431 - val_acc: 0.9540\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4946 - acc: 0.9510\n",
      " - 20s - loss: 0.0838 - acc: 0.9680 - val_loss: 0.4946 - val_acc: 0.9510\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5407 - acc: 0.9510\n",
      " - 19s - loss: 0.1144 - acc: 0.9550 - val_loss: 0.5407 - val_acc: 0.9510\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.6155 - acc: 0.9390\n",
      " - 19s - loss: 0.1008 - acc: 0.9655 - val_loss: 0.6155 - val_acc: 0.9390\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5620 - acc: 0.9460\n",
      " - 19s - loss: 0.1089 - acc: 0.9660 - val_loss: 0.5620 - val_acc: 0.9460\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5233 - acc: 0.9500\n",
      " - 20s - loss: 0.0945 - acc: 0.9660 - val_loss: 0.5233 - val_acc: 0.9500\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4902 - acc: 0.9510\n",
      " - 19s - loss: 0.1092 - acc: 0.9550 - val_loss: 0.4902 - val_acc: 0.9510\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5999 - acc: 0.9350\n",
      " - 19s - loss: 0.1004 - acc: 0.9595 - val_loss: 0.5999 - val_acc: 0.9350\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.4965 - acc: 0.9500\n",
      " - 19s - loss: 0.1080 - acc: 0.9595 - val_loss: 0.4965 - val_acc: 0.9500\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 5s 102ms/step - loss: 0.5361 - acc: 0.9480\n",
      " - 21s - loss: 0.0919 - acc: 0.9600 - val_loss: 0.5361 - val_acc: 0.9480\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4729 - acc: 0.9500\n",
      " - 19s - loss: 0.1198 - acc: 0.9545 - val_loss: 0.4729 - val_acc: 0.9500\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5252 - acc: 0.9480\n",
      " - 19s - loss: 0.0987 - acc: 0.9590 - val_loss: 0.5252 - val_acc: 0.9480\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.6518 - acc: 0.9400\n",
      " - 19s - loss: 0.1091 - acc: 0.9595 - val_loss: 0.6518 - val_acc: 0.9400\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 5s 106ms/step - loss: 0.4857 - acc: 0.9480\n",
      " - 20s - loss: 0.0961 - acc: 0.9670 - val_loss: 0.4857 - val_acc: 0.9480\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.3774 - acc: 0.9550\n",
      " - 19s - loss: 0.1110 - acc: 0.9565 - val_loss: 0.3774 - val_acc: 0.9550\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4307 - acc: 0.9510\n",
      " - 19s - loss: 0.1004 - acc: 0.9670 - val_loss: 0.4307 - val_acc: 0.9510\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 5s 100ms/step - loss: 0.5587 - acc: 0.9450\n",
      " - 19s - loss: 0.1050 - acc: 0.9615 - val_loss: 0.5587 - val_acc: 0.9450\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 0.5498 - acc: 0.9470\n",
      " - 19s - loss: 0.0965 - acc: 0.9640 - val_loss: 0.5498 - val_acc: 0.9470\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3954 - acc: 0.9560\n",
      " - 20s - loss: 0.1009 - acc: 0.9620 - val_loss: 0.3954 - val_acc: 0.9560\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3804 - acc: 0.9560\n",
      " - 19s - loss: 0.0823 - acc: 0.9720 - val_loss: 0.3804 - val_acc: 0.9560\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5273 - acc: 0.9420\n",
      " - 19s - loss: 0.0935 - acc: 0.9620 - val_loss: 0.5273 - val_acc: 0.9420\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3908 - acc: 0.9560\n",
      " - 19s - loss: 0.0991 - acc: 0.9645 - val_loss: 0.3908 - val_acc: 0.9560\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.4229 - acc: 0.9570\n",
      " - 20s - loss: 0.0798 - acc: 0.9700 - val_loss: 0.4229 - val_acc: 0.9570\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3787 - acc: 0.9580\n",
      " - 19s - loss: 0.0911 - acc: 0.9660 - val_loss: 0.3787 - val_acc: 0.9580\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.4765 - acc: 0.9490\n",
      " - 19s - loss: 0.0833 - acc: 0.9670 - val_loss: 0.4765 - val_acc: 0.9490\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 5s 102ms/step - loss: 0.4184 - acc: 0.9560\n",
      " - 20s - loss: 0.0898 - acc: 0.9710 - val_loss: 0.4184 - val_acc: 0.9560\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3870 - acc: 0.9580\n",
      " - 20s - loss: 0.0920 - acc: 0.9680 - val_loss: 0.3870 - val_acc: 0.9580\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5132 - acc: 0.9470\n",
      " - 19s - loss: 0.0809 - acc: 0.9695 - val_loss: 0.5132 - val_acc: 0.9470\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4771 - acc: 0.9510\n",
      " - 19s - loss: 0.0995 - acc: 0.9630 - val_loss: 0.4771 - val_acc: 0.9510\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.4125 - acc: 0.9590\n",
      " - 19s - loss: 0.0829 - acc: 0.9670 - val_loss: 0.4125 - val_acc: 0.9590\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 0.4376 - acc: 0.9570\n",
      " - 20s - loss: 0.0730 - acc: 0.9720 - val_loss: 0.4376 - val_acc: 0.9570\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4730 - acc: 0.9540\n",
      " - 19s - loss: 0.1058 - acc: 0.9615 - val_loss: 0.4730 - val_acc: 0.9540\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5026 - acc: 0.9530\n",
      " - 20s - loss: 0.0733 - acc: 0.9695 - val_loss: 0.5026 - val_acc: 0.9530\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4726 - acc: 0.9520\n",
      " - 19s - loss: 0.0967 - acc: 0.9605 - val_loss: 0.4726 - val_acc: 0.9520\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.6008 - acc: 0.9430\n",
      " - 20s - loss: 0.0797 - acc: 0.9710 - val_loss: 0.6008 - val_acc: 0.9430\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.5756 - acc: 0.9410\n",
      " - 19s - loss: 0.1072 - acc: 0.9605 - val_loss: 0.5756 - val_acc: 0.9410\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.6058 - acc: 0.9440\n",
      " - 19s - loss: 0.0796 - acc: 0.9705 - val_loss: 0.6058 - val_acc: 0.9440\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5360 - acc: 0.9500\n",
      " - 19s - loss: 0.0926 - acc: 0.9645 - val_loss: 0.5360 - val_acc: 0.9500\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 5s 103ms/step - loss: 0.4965 - acc: 0.9540\n",
      " - 19s - loss: 0.0756 - acc: 0.9675 - val_loss: 0.4965 - val_acc: 0.9540\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4899 - acc: 0.9510\n",
      " - 20s - loss: 0.0881 - acc: 0.9675 - val_loss: 0.4899 - val_acc: 0.9510\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4191 - acc: 0.9560\n",
      " - 19s - loss: 0.0942 - acc: 0.9670 - val_loss: 0.4191 - val_acc: 0.9560\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 5s 108ms/step - loss: 0.6079 - acc: 0.9450\n",
      " - 20s - loss: 0.0756 - acc: 0.9705 - val_loss: 0.6079 - val_acc: 0.9450\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.5629 - acc: 0.9460\n",
      " - 19s - loss: 0.0958 - acc: 0.9590 - val_loss: 0.5629 - val_acc: 0.9460\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.5856 - acc: 0.9450\n",
      " - 20s - loss: 0.1042 - acc: 0.9645 - val_loss: 0.5856 - val_acc: 0.9450\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4684 - acc: 0.9550\n",
      " - 19s - loss: 0.0938 - acc: 0.9655 - val_loss: 0.4684 - val_acc: 0.9550\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5715 - acc: 0.9430\n",
      " - 19s - loss: 0.0855 - acc: 0.9680 - val_loss: 0.5715 - val_acc: 0.9430\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4506 - acc: 0.9550\n",
      " - 19s - loss: 0.1004 - acc: 0.9640 - val_loss: 0.4506 - val_acc: 0.9550\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4540 - acc: 0.9520\n",
      " - 20s - loss: 0.0908 - acc: 0.9665 - val_loss: 0.4540 - val_acc: 0.9520\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4598 - acc: 0.9590\n",
      " - 19s - loss: 0.0630 - acc: 0.9745 - val_loss: 0.4598 - val_acc: 0.9590\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.3915 - acc: 0.9620\n",
      " - 19s - loss: 0.0893 - acc: 0.9615 - val_loss: 0.3915 - val_acc: 0.9620\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5842 - acc: 0.9390\n",
      " - 19s - loss: 0.0905 - acc: 0.9655 - val_loss: 0.5842 - val_acc: 0.9390\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 5s 98ms/step - loss: 0.4013 - acc: 0.9560\n",
      " - 20s - loss: 0.0851 - acc: 0.9700 - val_loss: 0.4013 - val_acc: 0.9560\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.4544 - acc: 0.9530\n",
      " - 19s - loss: 0.0826 - acc: 0.9700 - val_loss: 0.4544 - val_acc: 0.9530\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.5420 - acc: 0.9430\n",
      " - 19s - loss: 0.0883 - acc: 0.9675 - val_loss: 0.5420 - val_acc: 0.9430\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.5999 - acc: 0.9460\n",
      " - 19s - loss: 0.0802 - acc: 0.9670 - val_loss: 0.5999 - val_acc: 0.9460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "            training_data_generator,\n",
    "            validation_data = validation_data_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 100,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL",
    "outputId": "5c906d05-38e2-4513-c39b-28efda62de75"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting basic model information to plot.\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plotting accuracy and loss values for both traingin and validation sets.\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "# I still got a pretty bad validation for my validation set."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer_Learning_Cat_or_Dog.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
